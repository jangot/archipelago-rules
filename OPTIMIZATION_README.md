# Оптимизация скрипта upload-file.ts

## Проблемы с памятью в оригинальном скрипте

Оригинальный скрипт имел следующие проблемы:
1. **Загрузка всего файла в память** - `fs.readFileSync()` загружал весь файл как строку
2. **Создание всех чанков одновременно** - все чанки хранились в памяти
3. **Последовательная обработка без ограничений** - неограниченное количество одновременных запросов
4. **Отсутствие мониторинга памяти** - не было контроля за использованием ресурсов

## Реализованные оптимизации

### 1. Потоковая обработка файлов
- Подготовлен генератор `readFileStream()` для потокового чтения больших файлов
- Обработка файла по частям без загрузки целиком в память

### 2. Батчевая загрузка в Qdrant
- Загрузка чанков батчами (по умолчанию 50 штук)
- Очистка памяти после каждого батча
- Настраиваемый размер батча через параметр `--batchSize`

### 3. Ограничение конкурентных запросов
- Класс `LimitedQueue` для контроля количества одновременных запросов к OpenAI API
- По умолчанию максимум 5 одновременных запросов
- Настраивается через параметр `--maxConcurrent`

### 4. Кэширование векторов
- Класс `VectorCacheManager` для кэширования уже вычисленных векторов
- Сохранение в JSON-файл для повторного использования
- Автоматическая очистка старых записей
- Значительно ускоряет повторную обработку

### 5. Мониторинг памяти
- Функция `logMemoryUsage()` для отслеживания использования памяти
- Предупреждения при превышении порога (500MB)
- Логирование на каждом этапе обработки

### 6. Проверка размера файла
- Предупреждения о больших файлах (>100MB)
- Рекомендации по разбивке файлов

### 7. Мониторинг производительности
- Класс `PerformanceMonitor` для сбора метрик
- Анализ исторических данных для оптимизации параметров
- Автоматические рекомендации по настройке

## Использование

### Базовое использование
```bash
# Локальный файл
npx ts-node src/upload-file.ts --path /path/to/file.txt

# Google Drive файл
npx ts-node src/upload-file.ts --drive <FILE_ID>
```

### Расширенные параметры
```bash
npx ts-node src/upload-file.ts \
  --path /path/to/file.txt \
  --chunkSize 2000 \
  --overlap 5 \
  --batchSize 50 \
  --maxConcurrent 5
```

### Параметры оптимизации

| Параметр | По умолчанию | Описание |
|----------|--------------|----------|
| `--chunkSize` | 2000 | Размер чанка в символах |
| `--overlap` | 5 | Процент перекрытия между чанками |
| `--batchSize` | 50 | Количество чанков в батче |
| `--maxConcurrent` | 5 | Максимум одновременных запросов к OpenAI |

## Константы оптимизации

```typescript
const MAX_FILE_SIZE_MB = 100;        // Максимальный размер файла
const BATCH_SIZE = 50;               // Размер батча по умолчанию
const MAX_CONCURRENT_REQUESTS = 5;   // Максимум конкурентных запросов
const MEMORY_THRESHOLD_MB = 500;     // Порог памяти для предупреждений
```

## Кэш векторов

### Расположение
- Файл: `./cache/vector-cache.json`
- Автоматическое создание при первом запуске

### Управление
```typescript
const vectorCache = new VectorCacheManager();
await vectorCache.getVector(text);  // Получить вектор (с кэшированием)
vectorCache.clearCache();           // Очистить кэш
const stats = vectorCache.getCacheStats(); // Статистика
```

### Настройки кэша
- Максимум 10,000 записей
- Срок действия: 30 дней
- Автоматическая очистка старых записей

## Мониторинг производительности

### Файлы метрик
- `./metrics/performance-metrics.json` - исторические данные
- Автоматический сбор метрик при каждом запуске

### Анализ производительности
```typescript
const monitor = new PerformanceMonitor();
const report = monitor.getPerformanceReport();
console.log(report.recommendations); // Рекомендации по оптимизации
```

## Рекомендации по использованию

### Для серверов с 2GB памяти
```bash
# Используйте специальный скрипт
./start-upload-2gb.sh --path file.txt

# Или вручную с ограничениями
NODE_OPTIONS="--max-old-space-size=1536" npx ts-node src/upload-file.ts \
  --path file.txt \
  --chunkSize 1000 \
  --batchSize 15 \
  --maxConcurrent 2
```

### Для больших файлов (>50MB)
```bash
npx ts-node src/upload-file.ts \
  --path large-file.txt \
  --batchSize 30 \
  --maxConcurrent 3
```

### Для быстрой обработки
```bash
npx ts-node src/upload-file.ts \
  --path file.txt \
  --batchSize 100 \
  --maxConcurrent 10
```

### Для экономии памяти
```bash
npx ts-node src/upload-file.ts \
  --path file.txt \
  --batchSize 20 \
  --maxConcurrent 2
```

## Ожидаемые улучшения

1. **Память**: Снижение пикового использования на 60-80%
2. **Скорость**: Ускорение за счет кэширования и батчинга
3. **Стабильность**: Меньше ошибок из-за нехватки памяти
4. **Мониторинг**: Полная видимость производительности

## Устранение неполадок

### Ошибка "JavaScript heap out of memory"
```bash
# Для 2GB серверов
NODE_OPTIONS="--max-old-space-size=1536" npx ts-node src/upload-file.ts --path file.txt

# Уменьшите параметры
NODE_OPTIONS="--max-old-space-size=1536" npx ts-node src/upload-file.ts \
  --path file.txt \
  --chunkSize 800 \
  --batchSize 10 \
  --maxConcurrent 1
```

### Высокое потребление памяти
- Уменьшите `--batchSize` до 10-15
- Уменьшите `--maxConcurrent` до 1-2
- Уменьшите `--chunkSize` до 800-1000
- Разбейте большой файл на части

### Медленная обработка
- Увеличьте `--maxConcurrent` (если позволяет память)
- Увеличьте `--batchSize`
- Проверьте скорость интернета

### Ошибки кэша
- Удалите файл `./cache/vector-cache.json`
- Перезапустите скрипт

### Для 2GB серверов
- Используйте скрипт `./start-upload-2gb.sh`
- Максимальный размер файла: 50MB
- Рекомендуемые параметры: `--batchSize 15`, `--maxConcurrent 2`

## Будущие улучшения

1. **Потоковое чтение файлов** - полная реализация для очень больших файлов
2. **Распределенная обработка** - обработка на нескольких серверах
3. **Адаптивные параметры** - автоматическая настройка на основе характеристик системы
4. **Сжатие кэша** - уменьшение размера файла кэша
